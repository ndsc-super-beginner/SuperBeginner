{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "21f85dfd5b9bf3d8b27ba29149d52253e5d64049"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "78578eab64a477d0a5ad6b1c917ae154868a44df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>title</th>\n",
       "      <th>Category</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>605940</th>\n",
       "      <td>944297376</td>\n",
       "      <td>iphone 8 64gb garansi internasional</td>\n",
       "      <td>31</td>\n",
       "      <td>mobile_image/9bc1ddd0d2dffe99376ae6717a790323.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293998</th>\n",
       "      <td>289400312</td>\n",
       "      <td>baju branded murah enfocus black floral layere...</td>\n",
       "      <td>19</td>\n",
       "      <td>fashion_image/c276bf3a21e72efb84c5487a9acadfd7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44550</th>\n",
       "      <td>1378388079</td>\n",
       "      <td>unik wardah everyday luminous liquid foundation</td>\n",
       "      <td>1</td>\n",
       "      <td>beauty_image/6bd7cebd2eb445b5cd42b3267e71a3f1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58063</th>\n",
       "      <td>548524882</td>\n",
       "      <td>peripera blur pang peach milk spf30 pa</td>\n",
       "      <td>9</td>\n",
       "      <td>beauty_image/954202b23d8aba3dad4262dda3b959e2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505984</th>\n",
       "      <td>1011955231</td>\n",
       "      <td>kaos polos lengan panjang ft0009</td>\n",
       "      <td>25</td>\n",
       "      <td>fashion_image/50298ad1451aea1f20cba930dcec404e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            itemid                                              title  \\\n",
       "605940   944297376                iphone 8 64gb garansi internasional   \n",
       "293998   289400312  baju branded murah enfocus black floral layere...   \n",
       "44550   1378388079    unik wardah everyday luminous liquid foundation   \n",
       "58063    548524882             peripera blur pang peach milk spf30 pa   \n",
       "505984  1011955231                   kaos polos lengan panjang ft0009   \n",
       "\n",
       "        Category                                         image_path  \n",
       "605940        31  mobile_image/9bc1ddd0d2dffe99376ae6717a790323.jpg  \n",
       "293998        19     fashion_image/c276bf3a21e72efb84c5487a9acadfd7  \n",
       "44550          1  beauty_image/6bd7cebd2eb445b5cd42b3267e71a3f1.jpg  \n",
       "58063          9  beauty_image/954202b23d8aba3dad4262dda3b959e2.jpg  \n",
       "505984        25     fashion_image/50298ad1451aea1f20cba930dcec404e  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"./input/train.csv\")\n",
    "train_df = train_df.sample(frac=1.)\n",
    "val_df = train_df[:400]\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "92ffbf2ef35d2dc5863ee27c61eadd1869ca5440"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2196018it [02:20, 15585.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2196017 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Embdedding setup, save it in a dictionary for easier queries\n",
    "embeddings_index = {}\n",
    "f = open('./input/test-glove.txt')\n",
    "for line in tqdm(f):\n",
    "    values = line.split(\" \")\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "656aac528a152225f0150ed2be209003f07ebbc1"
   },
   "outputs": [],
   "source": [
    "# Convert values to embeddings\n",
    "def text_to_array(text):\n",
    "    empyt_emb = np.zeros(300)\n",
    "    text = text[:-1].split()[:100]\n",
    "    embeds = [embeddings_index.get(x, empyt_emb) for x in text]\n",
    "    embeds+= [empyt_emb] * (100 - len(embeds))\n",
    "    return np.array(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "9cc8b0bcd285225ce651d024f506615d4656b9f7"
   },
   "outputs": [],
   "source": [
    "val_vects = np.array([text_to_array(X_text) for X_text in (val_df[\"title\"][:])])\n",
    "val_y_labels = np.array(val_df[\"Category\"])\n",
    "val_y = np.zeros((len(val_y_labels), 58))\n",
    "val_y[np.arange(len(val_y_labels)), val_y_labels] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "dd1ca77b4e449cd1c0d02c0ea2f1fa616e479117"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 100, 300)\n",
      "(128, 58)\n",
      "[[[ 0.25687     0.38291001 -0.40415001 ...  0.24779999 -0.77301002\n",
      "    0.67146999]\n",
      "  [-0.48943999  0.55361998  0.44624999 ... -0.38089001  0.079228\n",
      "   -0.001193  ]\n",
      "  [ 0.83092999  0.19035     0.24209    ... -0.26086    -0.92707998\n",
      "    0.47852999]\n",
      "  ...\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]\n",
      "\n",
      " [[ 0.50954002 -0.16789     0.32336    ...  0.41446     0.22989\n",
      "    0.44521999]\n",
      "  [-0.11186    -0.12540001  0.058243   ...  0.0011172   0.38797\n",
      "    0.56098002]\n",
      "  [-0.26808     0.20982     0.32896999 ...  0.25751999 -0.01517\n",
      "   -0.0042005 ]\n",
      "  ...\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]\n",
      "\n",
      " [[ 0.49079001  0.11214     0.13407999 ...  0.40307999 -0.56897998\n",
      "   -0.39552999]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [-0.17675     0.095372   -0.10494    ... -0.29139    -0.15103\n",
      "    0.0032968 ]\n",
      "  ...\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-0.88322002 -0.21276     0.098521   ...  0.17664     0.49645001\n",
      "    0.058839  ]\n",
      "  [ 0.37817001 -0.35376     0.31927001 ...  0.19719    -0.34053999\n",
      "   -0.096836  ]\n",
      "  [ 0.51050001 -0.11347    -0.24323    ...  0.57248998 -0.70242\n",
      "   -0.10752   ]\n",
      "  ...\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]\n",
      "\n",
      " [[-0.37898999  0.041352   -0.083947   ... -0.21303     0.041024\n",
      "   -0.019819  ]\n",
      "  [-0.88322002 -0.21276     0.098521   ...  0.17664     0.49645001\n",
      "    0.058839  ]\n",
      "  [-0.055769    0.24264    -0.10455    ...  0.39629    -0.5043\n",
      "   -0.41172999]\n",
      "  ...\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]\n",
      "\n",
      " [[ 0.31896001 -0.35148001  0.81339997 ...  0.26844001 -0.58083999\n",
      "   -0.16836999]\n",
      "  [ 0.31817999 -0.23512     0.59603    ...  0.41600999 -0.1323\n",
      "   -0.54378998]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  ...\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Understand what a batch is made of\n",
    "batch_size = 128\n",
    "i = 0\n",
    "texts = train_df.iloc[i*batch_size:(i+1)*batch_size, 1]\n",
    "text_arr = np.array([text_to_array(text) for text in texts])\n",
    "batch_labels = np.array(train_df[\"Category\"][i*batch_size:(i+1)*batch_size])\n",
    "batch_targets = np.zeros((batch_size, 58))\n",
    "batch_targets[np.arange(batch_size), batch_labels] = 1\n",
    "print(np.shape(text_arr))\n",
    "print(np.shape(batch_targets))\n",
    "print(text_arr)\n",
    "print(batch_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "0c950448e0717eaebb920d93cfdc6b4561e21853"
   },
   "outputs": [],
   "source": [
    "# Write generator, which \n",
    "batch_size = 128\n",
    "\n",
    "def batch_gen(train_df):\n",
    "    n_batches = math.floor(len(train_df) / batch_size)\n",
    "    while True: \n",
    "        train_df = train_df.sample(frac=1.)  # Shuffle the data.\n",
    "        for i in range(n_batches):\n",
    "            texts = train_df.iloc[i*batch_size:(i+1)*batch_size, 1]\n",
    "            text_arr = np.array([text_to_array(text) for text in texts])\n",
    "            batch_labels = np.array(train_df[\"Category\"][i*batch_size:(i+1)*batch_size])\n",
    "            batch_targets = np.zeros((batch_size, 58))\n",
    "            batch_targets[np.arange(batch_size), batch_labels] = 1\n",
    "            yield text_arr, batch_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "706c0224b6112e5a8f00ad25f35e90fbb9519a5f"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "798c303ec834fb530a60a1e590cfbd9a86f93fde"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3c854e350399>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCuDNNLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import CuDNNLSTM, Dense, Bidirectional, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9ad418c95b31ab5691d49b72c7c9622ef9ea42cf"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(CuDNNLSTM(64, return_sequences=True),\n",
    "                        input_shape=(100, 300)))\n",
    "model.add(Bidirectional(CuDNNLSTM(64)))\n",
    "model.add(Dense(58))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3f0b703ded691293450beb4ddf2d903d0e08c737",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mg = batch_gen(train_df)\n",
    "model.fit_generator(mg, epochs=20,\n",
    "                    steps_per_epoch=1000,\n",
    "                    validation_data=(val_vects, val_y),\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d6cdda0e301be0b84e826e29f0f3a85c41aa6da9"
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b58cd95254f41e5002a17de0c3feab54a5fc3c67"
   },
   "outputs": [],
   "source": [
    "# Make the prediction from the model\n",
    "batch_size = 256\n",
    "def batch_gen(test_df):\n",
    "    n_batches = math.ceil(len(test_df) / batch_size)\n",
    "    for i in range(n_batches):\n",
    "        texts = test_df.iloc[i*batch_size:(i+1)*batch_size, 1]\n",
    "        text_arr = np.array([text_to_array(text) for text in texts])\n",
    "        yield text_arr\n",
    "\n",
    "test_df = pd.read_csv(\"../input/ndsc-beginner/test.csv\")\n",
    "\n",
    "all_preds = []\n",
    "for x in tqdm(batch_gen(test_df)):\n",
    "    all_preds.extend(model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3e6ed54def110c881f401c6f8a844752baedcfbd"
   },
   "outputs": [],
   "source": [
    "print(np.shape(all_preds))\n",
    "y_te = [np.argmax(pred) for pred in all_preds]\n",
    "\n",
    "submit_df = pd.DataFrame({\"itemid\": test_df[\"itemid\"], \"Category\": y_te})\n",
    "submit_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "363548b1cd5de65abae88a3f2bc091ff76f2fc70"
   },
   "outputs": [],
   "source": [
    "submit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b6bef2cc99773ae5f27789d5c9f7275841fc0bdb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
